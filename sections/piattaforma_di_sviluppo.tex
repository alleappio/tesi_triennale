\section{Piattaforma di sviluppo}
In questa sezione si descrive come è composta e come è stata assemblata la piattaforma per lo sviluppo e il testing.
\subsection{Rover AgileX}
Il veicolo selezionato per lo sviluppo della presente tesi è un rover terrestre prodotto da AgileX, modello Hunter. Questo rover è dotato di un'interfaccia di controllo basata sul protocollo CAN (Controller Area Network), che consente una comunicazione efficiente e affidabile tra i diversi sistemi elettronici del veicolo. Il modello Hunter è stato scelto per le sue avanzate caratteristiche tecniche e per la sua versatilità, che lo rendono particolarmente adatto alle esigenze del progetto.

\noindent Oltre a fornire un'interfaccia per il controllo diretto, il veicolo è in grado di raccogliere e trasmettere una serie di dati diagnostici e operativi fondamentali per il monitoraggio e l'analisi delle sue prestazioni. Tra questi dati, un ruolo cruciale è ricoperto dall'odometria, che rappresenta la misura dello spostamento del veicolo basata sul movimento delle ruote. L'odometria è essenziale per la navigazione e la stima della posizione del rover, poiché permette di determinare il percorso seguito dal veicolo e la distanza percorsa. Questi dati, insieme ad altre informazioni sullo stato del veicolo, contribuiscono a garantire un controllo preciso e ad alimentare i sistemi di guida autonoma e remota previsti dal progetto.
\subsection{GPGPU e sensore lidar}
Un elemento cruciale per la realizzazione di questa tesi è stato l'identificazione e la selezione di un calcolatore embedded idoneo a gestire l'intera logica di controllo e la pianificazione, oltre alla scelta di un sensore in grado di fornire dati essenziali per la percezione dell'ambiente circostante.
\noindent Per il calcolatore embedded, è stata presa la decisione di impiegare una GPGPU (General Purpose Graphic Processing Unit), una scelta motivata dalla sua elevata capacità di elaborazione parallela, che risulta particolarmente vantaggiosa per eseguire complessi algoritmi di controllo e di pianificazione in tempo reale. La GPGPU selezionata opera con il sistema operativo Ubuntu 20.04, noto per la sua stabilità, ampia compatibilità con hardware di ultima generazione, e supporto per lo sviluppo di applicazioni avanzate, inclusi strumenti specifici per l'elaborazione grafica e la gestione di risorse computazionali.
\noindent Per quanto concerne il sensore, la scelta è ricaduta su un sensore Lidar (Light Detection and Ranging). Questo dispositivo sfrutta la tecnologia laser per determinare la distanza di vari punti nell'ambiente circostante, calcolando il tempo di ritorno dei raggi laser emessi. Il Lidar fornisce una mappa dettagliata della topografia dell'ambiente, consentendo al sistema di percezione di creare rappresentazioni tridimensionali accurate, fondamentali per il riconoscimento degli ostacoli, la navigazione e la pianificazione del percorso del veicolo. La combinazione di una GPGPU performante e un sensore Lidar avanzato rappresenta una solida base tecnologica per lo sviluppo di un sistema di guida autonoma e remota altamente efficiente.

